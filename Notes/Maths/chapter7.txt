what is EVT:
Study the probability distribution of a maximum or minimum value.
M_n = \max \{X_1, X_2, \dots, X_n\}
当  n \to \infty  时，  M_n  的分布趋向于什么样的形式。

what is return level:
重现期（Return Period）计算的，重现期是指在某个给定时间间隔内（例如 100 年），这种极端事件平均会发生一次的概率。
\text{Return Period} = -\frac{1}{1 - F(x)} / 2
其中：
	•	 F(x)  是 GEV 分布的 CDF 值，表示达到该损失水平的概率。
	•	 1 - F(x)  是该损失水平未发生的概率。
	•	取倒数可以得到发生这种极端事件的期望年数。


基于重现期，如果事件的重现期是  T  年，那么 Return Level  z_T  是指在这个时间内，极端事件（比如降雨量、洪水水位等）将会超过的水平。
根据 GEV 分布，Return Level 的公式为：
z_T = \mu + \frac{\sigma}{\xi} \left( \left( -\log \left( 1 - \frac{1}{T} \right) \right)^{-\xi} - 1 \right)
e.g
50 年一遇的降雨量是多少（即 Return Level 对应 50 年重现期的值）。
if return level=100mm, 在任何一年内，降雨量超过 100 毫米的概率是  \frac{1}{50}, 换句话说，100 毫米的降雨量每 50 年大约会发生一次。



7.1
EVT：Around the median, the data is not centrally distributed, but rather spread out. 在中位数附近，数据没有集中分布，而是分散得比较开。
-block maxima method, BMM  分块极值模型
-peaks-over-thresholdmethod, POT  高于阈值頂点模型
-Poisson Process

7.2
7.2.1 BMM
M_n = \max \{ X_1, X_2, \dots, X_n \}
P\{M_n \leq z\} = P\{X_1 \leq z, \cdots, X_n \leq z\} the probability that the maximum value of the n random variables does not exceed z.
Xn i.i.d this joint probability can be split into the product of a single probability: 
P\{X_1 \leq z\} \times P\{X_2 \leq z\} \times \cdots \times P\{X_n \leq z\}   cdf [F(z)]^n
  problem: F(n) often unknown, as n increases, this leads to fairly divergent results.

F^n(x) = P\left( \max\{ X_1, X_2, \dots, X_n \} \leq x \right) = [F(x)]^n，as  n \to \infty , the distribution of maximum values will tend to a stable distribution of extreme values. 
According to Fisher–Tippett–Gnedenko theorem, the distribution of the maximum values converges to one of three families of extreme values: 
•	Gumbel 分布（对数极值分布）
•	Fréchet 分布（重尾分布）
•	Weibull 分布（有限尾部分布）

7.2.2 rth largest order
Compensate for BMM: The parameter estimation of unknown distribution has great uncertainty.

7.2.3 POT
Sample observations above a threshold
  X - u  Conditional Excess Distribution   
Generalized Pareto Distribution, GPD

确定阈值：
平均超越函数（Mean Residual Life, MRL）
e(u) = E[X - u \mid X > u]， 随机变量X，阈值u










NLLH 全称为 Negative Log-Likelihood (NLLH)，即 负对数似然函数。它是统计建模、机器学习和金融极值理论（EVT）中常用的模型评估指标，用于衡量模型对数据的拟合程度。

🔍 1. 什么是对数似然函数（Log-Likelihood, LLH）？

在概率统计中，似然函数（Likelihood Function） 衡量的是给定模型参数下，观察到的数据出现的可能性。

假设你有一组观测数据 ￼，以及一个概率分布函数 ￼，其中 ￼ 是模型参数（比如正态分布的均值和方差）。

似然函数 定义为：

￼

由于在实际计算中，连乘的数值会变得非常小，通常会对似然函数取对数，得到 对数似然函数（Log-Likelihood, LLH）：

￼

🚫 2. 负对数似然函数（Negative Log-Likelihood, NLLH）

为了方便最小化损失（因为大多数优化算法是用来最小化目标函数的），我们通常取 负值：

￼
	•	数值越小，模型对数据的拟合越好。
	•	在机器学习（尤其是分类和回归）中，NLLH 是一个常用的损失函数。
	•	在极值理论中，广义帕累托分布（GPD） 拟合时，使用 NLLH 可以找到最优的参数（例如形状参数和尺度参数），使模型最能描述极端事件的分布。

📈 3. 在极值理论（EVT）中的应用

在你的代码中，函数 gpdFit() 使用了 极值理论中的广义帕累托分布（GPD） 对数据进行拟合。该函数内部通常会使用 NLLH 进行参数估计，公式如下：

￼

其中：
	•	￼ 是损失值。
	•	￼ 是形状参数（决定尾部厚度）。
	•	￼ 是尺度参数（决定分布的扩展程度）。

NLLH 的作用：
	•	在拟合时，算法会最小化 NLLH，以找到最优的 ￼ 和 ￼。
	•	通过对比不同模型（例如不同去簇窗口下的拟合），可以比较哪个模型最能准确描述极端损失。

📊 4. 为什么 NLLH 越小越好？
	•	NLLH 衡量的是模型对观测数据的“意外程度”。
	•	如果模型能更好地解释数据（即数据在模型的高概率区域内），NLLH 的值就会更小。
	•	在金融风险管理中，较小的 NLLH 值意味着模型对市场极端损失的拟合更精确，风险评估更可靠。

✅ 5. 直观例子

假设有两个模型 ￼ 和 ￼：

模型	NLLH 值
A	250.5
B	230.1

在这种情况下，模型 B 的拟合效果更好，因为它的 NLLH 值更小。

需要我为你演示如何在 R 语言中提取和比较 gpdFit() 的 NLLH 值吗？ 🚀
